
### 第一段创业：iOS浏览器Mammoth Web Browser，人生第一个产品完成了AI + 出海 + 变现，一个非常好的开始。
2019年，App Store的出现，是一个比较大转折点，让技术有了全球化变现的能力。
高中期间，做了IOS浏览器，Mammoth Web Browser（猛犸浏览器），使用by Copy模式，每卖一份就赚一份固定的销售额的这种模式。
在高中期间，实现稳定现金流，大概30万美金，成为了中国第一代软件出海的创业者。

鉴于当时国内app store没有成熟的支持渠道，产品在国内赚吆喝赢影响力。在国内论坛上发破解版本，从而获得一些资本界的关注，认识并加入了真格基金。

### 第二段创业： Magi，自动化知识图谱构建
Tomas Mikolov在google推出了一篇Paper叫Word2Vec，发现兴趣点在NLP，而不是在做浏览器。同时苹果在研发Apple Watch可穿戴设备，发现知识和用户之间的交互，相对于PC浏览器，存在新的机会。在可穿戴式设备上需要有高效紧凑的representation：知识图谱。

知识图谱构建和应用落地依赖大量的人类知识，投入到一种新技术的研发：Open Information Extraction，不需要提前定义schema或者规则，是一种schema-less的形式，使用无大纲的形式去提取。

AI在阅读一篇文章的时候，能自动识别实体以及关系，并提取出三元组，持续自动地构建一个知识图谱。

从2014年开始做到2018年做产品，**Magi**：AI可以去网络上看各种各样的文章，并持续构建知识图谱。

走最苦的一条路，bottom up，啥都自己做，模型自己做，infra自己搞，评测自己做，产品自己做。2-3周迭代一次，在AI领域，这是很缓慢的。

直到2019年，拿到GPT-3的Early Access，发现他的能力和自己训练的模型基本能力对等。虽然很贵，但是他是一个通解。

产品侧：严重低估了搜索引擎这件事。只看到了技术问题，却解决不了非技术的问题。搜索引擎和搜索元数据已经形成了一种互利互惠可循环的关系。重新做一个搜索引擎产品非常困难。

因此决策赶紧卖公司。

>感悟：以后你看中一个技术问题，且这个技术问题真的别人没解决的话，那他往往可能是符合第一性原理的。他是一个很重要待解决的问题。
>不想做垂直整合。

### Monica：绝佳的作为AI应用时代的门槛产品
在真格待了一年半，加入肖宏团队，一起做浏览器插件。

相比其他产品：Anything added dilutes everything else，你每增加一个东西都会稀释所有的价值。而浏览器插件不会。

浏览器插件是一个绝妙的观察用户到底在怎么用AI的一个窗口。他是一个空的Container，一个空的画布。它绝妙之处在于，他的功能增发其实是基于context。比如说，视频相关的，只会在你看youtube的时候出现，和自动编写或者文章改动的这些功能，只会在gmail或者google docs里出现。它消减了功能增加带来的复杂度爆炸问题。它并没有改变任何用户的习惯，你依然在使用你熟悉的gmail、youtube等。AI并没有侵入你的生活而改变什么，所以用户原本的轨迹不是被强行改的，是一个无偏的观测。

在monica资金流正向，增长还不错的时候，萌生了做浏览器的念头。
当时chrome插件市场头部插件在5000万DAU左右，但是整个Chrome浏览器的日活相比（20亿），占比非常低，很多用户也不知道浏览器能安装插件。为了能继续拓宽monica的用户量，不希望被插件所束缚，因此想做浏览器（4月份到9月份）。

后来意识到有问题：
一、训练端侧模型，但是做的是浏览器，和不上网这件事相违背；用户不关注是不是端侧，只关注效果。
二、想让AI接管用户的浏览器。和当前电脑是个人电脑这件事相违背，你无法接受一台电脑你和一个实习生（AI）在共同使用。人的参与会打破AI的observation。另外，一些GUI任务，其实人的操作会更快，AI每做一次点击，大概要5-10秒，实际并没有产生多大价值。
三、另外团队没有回答一个问题：做了这块浏览器之后，有什么事情是chrome + monica做不到的吗？ 好像没有。
四、没有解决分发问题：人类浏览器的迁移变革就两次：1. 网景 到 IE(windows预装) ，2. IE到chrome（IE遇到安全问题）。这两次的变革均是因为渠道分发导致的。在当前浏览器良好的时代，用户并没有多大意愿更换浏览器。
同时， The Browser Company产品Arc下架，给了很大的共鸣。渠道分发是一个非常困难的事情，创始人表示，做Arc浏览器这么久，却没有办法说服亲戚来使用Arc浏览器。

两段浏览器失败经历，重新对浏览器创业的认识：
**浏览器不适合以一个创业者或者说一个颠覆者的形态来做。更像是巨头你已经有了分发的渠道之后，去锦上添花的一件事。**

同时对于发布产品的思考：
如果自己都不觉得这个产品酷，那别人就更不会觉得这个产品酷。如果想要发出来让大家看看，就会不断进入自证循环的漩涡，需要一个负责任的团队就会去维护，带来很大的机会成本。从而错失明明更加有价值的新的机会。

最终，浏览器胎死腹中。

但是Monica是一次成功的创业，他为后续Manus带来了非常重要的意义：
一、Monica正向现金流产品，对后续做决策影响很大，团队做决策变得即大胆又理智。
二、Monica带来AI应用的用户画像，理解context的重要性。AI在观察Context，给了很大的启发。从一些用户数据中学习pattern。

### Manus：AI之手
AI coding产品的涌现，意识到编程不是个垂直领域，他是一个通用领域，coding只是一种媒介。cursor不断有非程序员使用，它的产品形态有优化空间，希望Agent能在云端执行，解放人类的attention，代码应该作为工具，而不是一个呈现。这个产品的主要用户并不是专业开发工程师，而是prosumers，所有的脑力工作者，但不是程序员。

模型解决的是智力，即使再聪明的AI，也不能将环境内化掉，需要一只手去触及到现实世界中。否则再强的思维，你也只是理论物理学家。Manus，让智能真正去触及现实世界。

Manus从24年9月底开始，到25年1月完成，但是当时sonnet3.5 V2在agent能力上依然还有问题，产品决策再等两个月，到sonnet 3.7发布，享受模型升级带来的一个代际提升（模型溢出）。


#### 产品上坚持做通用Agent
为什么做通用Agent，而不是做垂直Agent：
一、技术角度，垂直模型被大一统模型吃掉，而manus是一个非常通用的agent框架
manus的本质是一个模型加上一台虚拟机，图灵完备，理论上能做任何事情。
产品上并没有做特别大的Bet，而是一种类似于达尔文的心态在观察，我如果给用户提供的是一套通用的架构的话，那么我获得的优势是什么？用户可以发挥他的想象力，去使用这个产品，同时我们作为创建这个产品的人，我们的使命是通过观察用户的整体的collective集体的一个行为模式，发现头部场景，然后让产品团队去优化解决最后一公里的问题。

二、很多产品能力会被收敛，比如说deep research，很多公司都已经有了。manus通用的能力，可以cover到一些**长尾场景**，会产生aha moment

三、频次问题。旅行规划等，用户使用场景很低。如果做通用agent，可以cover用户的方方面面，会有更高的频次。


基础能力或者原子能力的网络效应：Manus增加能力非常谨慎。但是每次都要保证这个能力能跟别的能力形成组合拳。比如说，最早我们给manus加入了一个看图的能力，希望manus看一下它生成的图好不好，但后来发现加了看图或者多模态输入能力之后，manus开始自己学会检查自己做的网页是否能玩的通。你增加一个技术能力，能给你所有通用Agent这个水平别的能力之间产生交互。从而让Agent能力呈指数级上升。
Agent和Agent之间的网络效应：manus的wide research能力其实也算一种网络效应。agent之间可以相互通讯，去完成单独一个agent无法完成的任务。

Manus中很重要的概念：Connector，连接与集成。manus是一个agent，模仿一个人能用各种工具，具备设计能力，他可以调用lovart等工具做设计，比如说内部，经常manus调用manus自己。

#### 技术上坚持做纯血Agent
做Manus技术上非常坚持一件事：Manus是一个单独的Unified统一的Agent框架，用户在manus中进行不同任务的时候，他的上下文，他的记忆是可以自由流转的。所以我们做的事情就是跟垂直的功能相比，永远多做一步。

坚持做纯血派的Agent：没有人为加的约束，完成一个人物的所有的过程和方式是由智能本身决定的。这么设计他的天花板会非常高。不做以规则主导的agentic workflow。符合The bitter lesson：用通用的方法，投入更大的算力去解决问题，而不是加入更多的人为知识。
比如说，让Agent做数据可视化工作，比较简单的产品驱动方式，保障所有语言下的数据可视化效果非常好，不能因为有不同的语言而产生字体乱码问题。因此可能会写很多prompt去调整，写一大堆guardrails。每增加一条约束，其实你都在减小模型的多样性。manus的做法是，加入了一条查看图片的能力。期望智能体能自己查看这张图发现问题，从而自己去修改。

另外，不认同过于让Agent模仿人类的分工，应该站在模型的角度思考。

模型当前还在和chatbot做alignment，在agent上还有空间。对于模型具备200K上下文更重要的是，模型需要知道如何compact、offload、reload memory。

将一些数学、竞赛等思考模型挪到agent场景，发现效果是下降的。更改训练方式，interleaved thinking（交错式思考），模型在调用工具之前，先进行一小段思考。

### 四、关于AI创业：
很多创始人没有乔布斯的命，得了乔布斯的病。很多创始人都很艺术家，不适合当下AI。肖宏比较务实、数据驱动。
身心健康很重要，受挫是必然，需要身心健康的人打不死。

当前AI创业，更像是一个制造业，需要关注成本。整件事情对经营的操作能力要求是比上一代移动互联网创业又高很多的。

Manus追求的不是DAU，而是营收。
1. AI是以前工具的延伸：以前的优势可以惯性发挥，要充分利用好这一点。
2. AI更像一个制造业：边际成本

Research和Engineering是很深的耦合，产品同时在引导你的系统架构，需要合伙人扮演不同的岗位职责，需要自己领域做得深，但是又能听得进别人话的人。

团队的决策机制：GPA
Goal： 专制，一人独裁
Prority：专制 + 民主
Alternative：民主（数量比质量更重要）

产品上还没有想明白的时候，先做，拿到reward然后决定下一步。

整个公司基因是产品驱动。

产品和技术的关系：
技术服务于产品，而技术有一票否定权。比如说，产品有很多快糙猛的做法，比如为了修复一个产品体验放弃纯血Agent想法，技术会跳出来否定。

### 关于AI产品和模型
产品是否需要有Bet：
1. 产品迭代的速度会很快，成本也更低。产品需要掉头很快。
2. 相比于做模型公司，需要有技术Bet， 而做AI产品，你会进行一些轻量级、可逆的Bet，不能有很重的Bet。
3. 不做什么很重要：AI让大家的产能变得很大，大家眼中的机会很多，AI充分解放了生产力。每天都在回答，我要不做什么。每月都尝试删除掉什么。
4. 做产品美妙的地方就是，你可以定义什么是好，你起码能在一个错位的赛道上去跟别人竞争，有更多的发挥空间。

模型和产品的关系，什么时候开始训模型
1. 做模型不做到SOTA没有意义，而做SOTA模型的保质期只有1到1个半月。
2. 未来做大模型的公司，肯定会做应用。
3. 做大模型经验&知识的流通非常快，一家两口子可能一个在google上班一个在openai上班，公司之间没有秘密。最后会变成一个应用之争，每个应用后面会绑定一些模型，模型公司和应用公司之间不会泾渭分明。

因此一个比较健康的做法是：当你的产品已经初具PMF且到一定的稳定状态之后，你以一种增加稳定性、或降本、或突破天花板的思路再去做模型。

吃过两次亏：
吃亏一：在不确定的时候，做bottom up这种，你会被你的模型迭代速度影响。在模型正式被训练之前，哪怕在post training未完成之前，都不知道模型的能力边界在哪里。所以，往往是因为模型能力的一些突破，反向引导产品的走向。
吃亏二：模型训练速度即使通过很多的优化，或者增加人手，但是只要有产品经理的存在，一定是追不上产品经理的脑思维的活跃度。

相对于模型有明确的benchmark，做产品美妙的地方就是，你可以定义什么是好，你起码能在一个错位的赛道上去跟别人竞争，有更多的发挥空间。

Manus产品的壁垒：快！
一、不同场景，使用不同的模型，最熟悉模型，体验能做得最好
二、大厂做垂直整合不会快

接下去manus重要的方向：proactiveness
AI应用素：模型、人、环境
在人这块还有很大的提升空间，很多上下文并没有代入。接下去manus的一个方向，在做agent的proactiveness，也就是主动性。

### Agentic Model训练建议
1. 与其充分地去无限扩展context window，不如让模型学会compassion awareness。模型意识到上下文过长，知道何时去压缩，何时去offload、retrieve
2. reasoning优化目标：不要以缸中之脑的形式去做，应该更好地结合observation，有个词叫TIR（Tool-Integrated Reasoning）。它跟这种完全靠RLVR去解竞赛编程和数学是完全不一样的思路。
3. Human in the Loop：用户在Agent执行过程，可以随时插嘴。要么改变目标，要不补充信息，或者终止它。当前很多agentic模型并没有完全掌握的一个交互模式
4. Error Resilience：模型应该更关注一Error的c处理和恢复能力。实际上会有一些非代码性的错误，比如说做一个slides，或者做一个批量文件处理过程中，你一定会遇到很多意料之外的事情发生，会发现有些模型要么会放弃，要么陷入一种类似于死循环的状态。但是修改的模型应该是它永远能找到一条别的路去尝试。


manus的多模态做得怎么样：
更在意多模态的输入而不是多模态的输出。在agent场景下，开源的多模态模型在简单的interleaved图文输入情况下，都能获得比较好的结果，比如说VQA。在agent场景，有一类情况是多模态作为tool result，这个在当前训练过程中，目前的重视程度不够。